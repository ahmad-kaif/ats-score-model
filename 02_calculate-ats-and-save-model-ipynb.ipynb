{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":12249452,"sourceType":"datasetVersion","datasetId":7718284}],"dockerImageVersionId":31041,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-06-22T18:50:21.165322Z","iopub.execute_input":"2025-06-22T18:50:21.165887Z","iopub.status.idle":"2025-06-22T18:50:21.172844Z","shell.execute_reply.started":"2025-06-22T18:50:21.165862Z","shell.execute_reply":"2025-06-22T18:50:21.172317Z"}},"outputs":[{"name":"stdout","text":"/kaggle/input/ats-score-preprocessed-dataset/preprocessed_ats_dataset.csv\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"# â”€â”€â”€ Imports â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\nimport pandas as pd, numpy as np, joblib, re, pathlib, shutil\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\nfrom sklearn.metrics.pairwise import cosine_similarity\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sentence_transformers import SentenceTransformer\nimport spacy\n\n# â”€â”€â”€ Config â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\nDATA_PATH = \"/kaggle/input/ats-score-preprocessed-dataset/preprocessed_ats_dataset.csv\"   # update accordingly\nOUT_DIR   = pathlib.Path(\"/kaggle/working\")\nMODEL_DIR = OUT_DIR / \"miniLM_model\"\n\n# â”€â”€â”€ Load spaCy â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\ntry:\n    nlp = spacy.load(\"en_core_web_sm\", disable=[\"ner\", \"parser\"])\nexcept:\n    from spacy.cli import download\n    download(\"en_core_web_sm\")\n    nlp = spacy.load(\"en_core_web_sm\", disable=[\"ner\", \"parser\"])\n\nSPACY_STOP = nlp.Defaults.stop_words\nRE_NONWORD = re.compile(r\"\\W+\")\nRE_DIGITS  = re.compile(r\"\\d+\")\n\ndef preprocess(text):\n    text = RE_DIGITS.sub(\" \", RE_NONWORD.sub(\" \", str(text).lower()))\n    doc  = nlp(text)\n    return \" \".join(tok.lemma_ for tok in doc if tok.lemma_ not in SPACY_STOP and len(tok) > 1)\n\n# â”€â”€â”€ Load Dataset â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\ndf = pd.read_csv(DATA_PATH)\nrequired_cols = {\"Resume\", \"Job_Description\", \"Role\"}\nassert required_cols.issubset(df.columns), f\"Missing: {required_cols - set(df.columns)}\"\nprint(f\"âœ… Loaded {len(df)} rows\")\n\n# â”€â”€â”€ Preprocess â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\nprint(\"ðŸ”„ Preprocessingâ€¦\")\ndf[\"Resume_Clean\"] = df[\"Resume\"].map(preprocess)\ndf[\"JD_Clean\"]     = df[\"Job_Description\"].map(preprocess)\ndf[\"Role_Clean\"]   = df[\"Role\"].map(preprocess)\n\n# â”€â”€â”€ Train/Test Split â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\ntrain_df, test_df = train_test_split(df, test_size=0.2, random_state=42)\nprint(f\"ðŸ”€ Train: {len(train_df)} | Test: {len(test_df)}\")\n\n# â”€â”€â”€ Embedding Model â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\nprint(\"ðŸ”„ Embedding using Sentence-BERT\")\nsbert = SentenceTransformer(\"paraphrase-MiniLM-L3-v2\")\n\ndef compute_score(df_part):\n    res_vec  = sbert.encode(df_part[\"Resume_Clean\"].tolist(), convert_to_numpy=True, show_progress_bar=True)\n    jd_vec   = sbert.encode(df_part[\"JD_Clean\"].tolist(),     convert_to_numpy=True, show_progress_bar=True)\n    role_vec = sbert.encode(df_part[\"Role_Clean\"].tolist(),   convert_to_numpy=True, show_progress_bar=True)\n\n    sim_rj = cosine_similarity(res_vec, jd_vec).diagonal()\n    sim_rr = cosine_similarity(res_vec, role_vec).diagonal()\n\n    return sim_rj, sim_rr\n\nsim_rj_train, sim_rr_train = compute_score(train_df)\nscaler_rj = MinMaxScaler()\nscaler_rr = MinMaxScaler()\n\nsim_rj_train_scaled = scaler_rj.fit_transform(sim_rj_train.reshape(-1, 1)).ravel()\nsim_rr_train_scaled = scaler_rr.fit_transform(sim_rr_train.reshape(-1, 1)).ravel()\ntrain_df[\"ATS_Score\"] = np.round((0.7 * sim_rj_train_scaled + 0.3 * sim_rr_train_scaled) * 100, 2)\n\n# â”€â”€â”€ Use same scalers on test data â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\nsim_rj_test, sim_rr_test = compute_score(test_df)\nsim_rj_test_scaled = scaler_rj.transform(sim_rj_test.reshape(-1, 1)).ravel()\nsim_rr_test_scaled = scaler_rr.transform(sim_rr_test.reshape(-1, 1)).ravel()\ntest_df[\"ATS_Score\"] = np.round((0.7 * sim_rj_test_scaled + 0.3 * sim_rr_test_scaled) * 100, 2)\n\n# â”€â”€â”€ Save complete scored dataset â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\nscored_df = pd.concat([train_df, test_df], axis=0)\nscored_df.to_csv(OUT_DIR / \"ats_scored.csv\", index=False)\n\n# â”€â”€â”€ Regression Metrics â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n# [Optional] Simulated \"ground truth\" score for testing purpose\n# You can remove this if you plan to manually annotate or use real scores later\ntest_df[\"True_Score\"] = test_df[\"ATS_Score\"] + np.random.normal(0, 3, len(test_df))  # simulate some label noise\n\nmae  = mean_absolute_error(test_df[\"True_Score\"], test_df[\"ATS_Score\"])\nrmse = mean_squared_error(test_df[\"True_Score\"], test_df[\"ATS_Score\"], squared=False)\nr2   = r2_score(test_df[\"True_Score\"], test_df[\"ATS_Score\"])\n\nprint(f\"\\nðŸ“Š Regression Metrics on Test (simulated ground truth):\")\nprint(f\"MAE : {mae:.2f}   RMSE : {rmse:.2f}   RÂ² : {r2:.4f}\")\n\n# â”€â”€â”€ Save Artifacts â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\nprint(\"ðŸ’¾ Saving artifacts â€¦\")\nMODEL_DIR.mkdir(parents=True, exist_ok=True)\nsbert.save(str(MODEL_DIR))\njoblib.dump({\"rj\": scaler_rj, \"rr\": scaler_rr}, \"minmax_scaler.pkl\")\n\nshutil.make_archive(str(MODEL_DIR), \"zip\", str(MODEL_DIR))\n\nprint(\"âœ… All done.\")\nprint(scored_df[[\"Name\", \"Role\", \"ATS_Score\"]].sample(5).to_string(index=False))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-22T19:15:52.876174Z","iopub.execute_input":"2025-06-22T19:15:52.876758Z","iopub.status.idle":"2025-06-22T19:21:02.290924Z","shell.execute_reply.started":"2025-06-22T19:15:52.876735Z","shell.execute_reply":"2025-06-22T19:21:02.290134Z"}},"outputs":[{"name":"stdout","text":"âœ… Loaded 10171 rows\nðŸ”„ Preprocessingâ€¦\nðŸ”€ Train: 8136 | Test: 2035\nðŸ”„ Embedding using Sentence-BERT\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/255 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3a0e4ab552c34757bbec50ae2d3165a8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/255 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"791cb8d56b244a6ba08e78665e09f8a0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/255 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d9c7daa17b91412cb6964b8f46cd73d4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/64 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f4a7f53e53a64d9caa2304e1d4c3c582"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/64 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0df7dd8be29b4c20ae6a7ce045228eae"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/64 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9dbe1334ae14449d97f67d24ada01f84"}},"metadata":{}},{"name":"stdout","text":"\nðŸ“Š Regression Metrics on Test (simulated ground truth):\nMAE : 2.45   RMSE : 3.05   RÂ² : 0.9481\nðŸ’¾ Saving artifacts â€¦\nâœ… All done.\n            Name                 Role  ATS_Score\n     Fanish Basu      Project Manager  44.759998\n    saanvi kohli         data analyst  38.060001\n      niraj sahu    software engineer  39.840000\n    pratiti iyer        data engineer  53.320000\nVincent Williams Mobile App Developer  42.189999\n","output_type":"stream"}],"execution_count":11},{"cell_type":"code","source":"import joblib\nimport re\nimport spacy\nfrom sentence_transformers import SentenceTransformer\nfrom sklearn.metrics.pairwise import cosine_similarity\nimport numpy as np\n\n# â”€â”€ Load required models\nsbert = SentenceTransformer(\"/kaggle/working/miniLM_model\")\nscaler_rj = joblib.load(\"/kaggle/working/scaler_rj.pkl\")\nscaler_rr = joblib.load(\"/kaggle/working/scaler_rr.pkl\")\n\n# â”€â”€ spaCy init\nnlp = spacy.load(\"en_core_web_sm\", disable=[\"ner\", \"parser\"])\nSPACY_STOP = nlp.Defaults.stop_words\nRE_NONWORD = re.compile(r\"\\W+\")\nRE_DIGITS  = re.compile(r\"\\d+\")\n\ndef preprocess(text: str) -> str:\n    text = RE_DIGITS.sub(\" \", RE_NONWORD.sub(\" \", text.lower()))\n    doc = nlp(text)\n    return \" \".join(tok.lemma_ for tok in doc if len(tok) > 1 and tok.lemma_ not in SPACY_STOP)\n\n# â”€â”€ YOUR INPUT\nresume = \"\"\"Skilled MERN Stack Developer with experience in React, Node.js, Express, MongoDB, and NLP projects. Built ATS resume checker using ML and Gemini LLM.\"\"\"\njob_description = \"\"\"We are looking for a Full-Stack Developer proficient in React, Node.js, and modern AI/NLP tools to build web-based ML products.\"\"\"\nrole = \"Full Stack Developer\"\n\n# â”€â”€ Preprocess\nres_clean = preprocess(resume)\njd_clean  = preprocess(job_description)\nrole_clean = preprocess(role)\n\n# â”€â”€ Encode using SBERT\nres_vec, jd_vec, role_vec = sbert.encode(\n    [res_clean, jd_clean, role_clean], convert_to_numpy=True\n)\n\n# â”€â”€ Compute similarities\nsim_rj = cosine_similarity([res_vec], [jd_vec])[0][0]\nsim_rr = cosine_similarity([res_vec], [role_vec])[0][0]\n\n# â”€â”€ Scale similarities\nsim_rj_scaled = scaler_rj.transform([[sim_rj]])[0][0]\nsim_rr_scaled = scaler_rr.transform([[sim_rr]])[0][0]\n\n# â”€â”€ Final ATS score\nats_score = round((0.7 * sim_rj_scaled + 0.3 * sim_rr_scaled) * 100, 2)\n\n# â”€â”€ Output\nprint(\"ðŸŽ¯ ATS Score:\", ats_score)\nprint(\"Similarity (Resume â†” JD):\", round(sim_rj, 4))\nprint(\"Similarity (Resume â†” Role):\", round(sim_rr, 4))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-22T19:07:23.500709Z","iopub.execute_input":"2025-06-22T19:07:23.501444Z","iopub.status.idle":"2025-06-22T19:07:24.209227Z","shell.execute_reply.started":"2025-06-22T19:07:23.501419Z","shell.execute_reply":"2025-06-22T19:07:24.208653Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5f15bf003ba24169ba50812e59880be0"}},"metadata":{}},{"name":"stdout","text":"ðŸŽ¯ ATS Score: 73.9\nSimilarity (Resume â†” JD): 0.6019\nSimilarity (Resume â†” Role): 0.4788\n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}